{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c35d16fb",
   "metadata": {},
   "source": [
    "# Training a Healthy Meal Classifier\n",
    "\n",
    "This notebook trains a simple classifier that predicts whether a meal is\n",
    "\"healthy\" or \"unhealthy\" based on its nutritional values.\n",
    "\n",
    "- Input data: `dataset/healthy_eating_dataset.csv`\n",
    "- Target column: `is_healthy` (0 = unhealthy, 1 = healthy)\n",
    "- Features used:\n",
    "  - calories\n",
    "  - protein_g\n",
    "  - carbs_g\n",
    "  - fat_g\n",
    "  - fiber_g\n",
    "  - sugar_g\n",
    "  - sodium_mg\n",
    "\n",
    "We will train a Logistic Regression model with class balancing to handle\n",
    "the imbalance between healthy and unhealthy meals, evaluate it, and save\n",
    "the trained pipeline to `models/health_classifier.joblib`.\n",
    "\n",
    "This model will later be used inside the agent as a tool.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3857cc7f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0858ead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    balanced_accuracy_score\n",
    ")\n",
    "\n",
    "import joblib\n",
    "\n",
    "\n",
    "\n",
    "# Make sure relative paths are from project root when you run this notebook.\n",
    "BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\")))\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"dataset\")\n",
    "MODELS_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Base dir:\", BASE_DIR)\n",
    "print(\"Data dir:\", DATA_DIR)\n",
    "print(\"Models dir:\", MODELS_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870eb969",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c5afb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_csv_path = os.path.join(DATA_DIR, \"healthy_eating_dataset.csv\")\n",
    "\n",
    "print(\"Healthy dataset path:\", healthy_csv_path)\n",
    "\n",
    "df = pd.read_csv(healthy_csv_path)\n",
    "print(\"Healthy dataset shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13306dc5",
   "metadata": {},
   "source": [
    "## General infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafe4a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "\n",
    "print(\"\\nClass distribution for is_healthy:\")\n",
    "print(df[\"is_healthy\"].value_counts())\n",
    "\n",
    "print(\"\\nClass proportion:\")\n",
    "print(df[\"is_healthy\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c6ef45",
   "metadata": {},
   "source": [
    "## Cleaning and sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd4ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_COLUMNS = [\n",
    "    \"calories\",\n",
    "    \"protein_g\",\n",
    "    \"carbs_g\",\n",
    "    \"fat_g\",\n",
    "    \"fiber_g\",\n",
    "    \"sugar_g\",\n",
    "    \"sodium_mg\",\n",
    "]\n",
    "\n",
    "TARGET_COLUMN = \"is_healthy\"\n",
    "\n",
    "# Remove exact duplicates\n",
    "before = df.shape[0]\n",
    "df = df.drop_duplicates()\n",
    "after = df.shape[0]\n",
    "print(f\"Removed {before - after} duplicate rows.\")\n",
    "\n",
    "# Drop rows with missing values in features or target\n",
    "df = df.dropna(subset=FEATURE_COLUMNS + [TARGET_COLUMN])\n",
    "\n",
    "# Simple numerical sanity filters (values outside are highly unlikely)\n",
    "df = df[\n",
    "    (df[\"calories\"] > 0)\n",
    "    & (df[\"protein_g\"] >= 0)\n",
    "    & (df[\"carbs_g\"] >= 0)\n",
    "    & (df[\"fat_g\"] >= 0)\n",
    "    & (df[\"fiber_g\"] >= 0)\n",
    "    & (df[\"sugar_g\"] >= 0)\n",
    "    & (df[\"sodium_mg\"] >= 0)\n",
    "]\n",
    "\n",
    "print(\"\\nDataset shape after basic cleaning:\", df.shape)\n",
    "\n",
    "df[FEATURE_COLUMNS].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8799c0",
   "metadata": {},
   "source": [
    "# Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea304df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[FEATURE_COLUMNS].values\n",
    "y = df[TARGET_COLUMN].values\n",
    "\n",
    "# 1) Split test (benchmark final)\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "# 2) Split validation (pour choisir le threshold)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    test_size=0.2,      # 20% de (train_full) => 16% du dataset total\n",
    "    random_state=42,\n",
    "    stratify=y_train_full,\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape[0])\n",
    "print(\"Val size:  \", X_val.shape[0])\n",
    "print(\"Test size: \", X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5cefd0",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d15d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(\n",
    "    class_weight=\"balanced\",  # handle class imbalance\n",
    "    max_iter=500,\n",
    "    solver=\"liblinear\",\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", log_reg),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbea6a4",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb725ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "y_proba_val = pipeline.predict_proba(X_val)[:, 1]  # proba classe 1 (healthy)\n",
    "\n",
    "print(\"Training completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba08cf0",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a7c419",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = pipeline.predict_proba(X_test)[:, 1]  # probability of class 1 (healthy)\n",
    "y_pred_05 = (y_proba >= 0.5).astype(int)\n",
    "\n",
    "print(\"=== Evaluation with default threshold 0.5 ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_05):.3f}\")\n",
    "print(f\"ROC-AUC:  {roc_auc_score(y_test, y_proba):.3f}\")\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred_05))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_05))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1878689",
   "metadata": {},
   "source": [
    "## Treshold for healthy class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f337bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def pick_threshold_balanced_accuracy(y_true, y_proba, step=0.01):\n",
    "    thresholds = np.arange(0.0, 1.0 + step, step)\n",
    "\n",
    "    best_thr = 0.5\n",
    "    best_score = -1.0\n",
    "    best_row = None\n",
    "\n",
    "    for thr in thresholds:\n",
    "        y_pred = (y_proba >= thr).astype(int)\n",
    "\n",
    "        # Balanced accuracy\n",
    "        bal_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "\n",
    "        # Extra metrics (useful to report)\n",
    "        prec = precision_score(y_true, y_pred, pos_label=1, zero_division=0)\n",
    "        rec = recall_score(y_true, y_pred, pos_label=1, zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, pos_label=1, zero_division=0)\n",
    "\n",
    "        if bal_acc > best_score:\n",
    "            best_score = bal_acc\n",
    "            best_thr = thr\n",
    "            best_row = (bal_acc, prec, rec, f1)\n",
    "\n",
    "    return best_thr, best_row\n",
    "\n",
    "best_thr, (bal_acc, prec, rec, f1) = pick_threshold_balanced_accuracy(y_val, y_proba_val, step=0.01)\n",
    "\n",
    "print(\"Selected threshold (max balanced accuracy):\", round(best_thr, 2))\n",
    "print(\"Validation metrics at threshold:\",\n",
    "      f\"balanced_acc={bal_acc:.3f}, precision={prec:.3f}, recall={rec:.3f}, f1={f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e1b6ac",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bc430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba_test = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Baseline 0.5\n",
    "y_pred_05 = (y_proba_test >= 0.5).astype(int)\n",
    "\n",
    "# Tuned threshold (choisi sur val)\n",
    "y_pred_best = (y_proba_test >= best_thr).astype(int)\n",
    "\n",
    "print(\"=== TEST with threshold 0.5 (baseline) ===\")\n",
    "print(confusion_matrix(y_test, y_pred_05))\n",
    "print(classification_report(y_test, y_pred_05))\n",
    "\n",
    "print(\"\\n=== TEST with tuned threshold (from VAL) ===\")\n",
    "print(\"Chosen threshold:\", best_thr)\n",
    "print(confusion_matrix(y_test, y_pred_best))\n",
    "print(classification_report(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2396ceda",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4981998",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(MODELS_DIR, \"health_classifier.joblib\")\n",
    "model_bundle = {\n",
    "    \"pipeline\": pipeline,\n",
    "    \"feature_columns\": FEATURE_COLUMNS,\n",
    "    \"decision_threshold\": float(best_thr),\n",
    "}\n",
    "\n",
    "joblib.dump(model_bundle, model_path)\n",
    "\n",
    "print(f\"Saved health classifier to: {model_path}\")\n",
    "print(\"Decision threshold stored:\", best_thr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7f7bec",
   "metadata": {},
   "source": [
    "# Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e4bcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = joblib.load(model_path)\n",
    "loaded_pipeline = loaded[\"pipeline\"]\n",
    "loaded_features = loaded[\"feature_columns\"]\n",
    "loaded_thr = loaded[\"decision_threshold\"]\n",
    "\n",
    "print(\"Loaded feature columns:\", loaded_features)\n",
    "print(\"Loaded decision threshold:\", loaded_thr)\n",
    "\n",
    "sample = X_test[0:1]\n",
    "proba = loaded_pipeline.predict_proba(sample)[0, 1]\n",
    "pred = int(proba >= loaded_thr)\n",
    "\n",
    "print(\"Example probability of being healthy:\", proba)\n",
    "print(\"Example prediction with threshold:\", pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
